{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f8accf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "875acd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a199a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "debc88eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   _STATE  FMONTH    IDATE  IMONTH  IDAY  IYEAR  DISPCODE       SEQNO  \\\n",
      "0     2.0     5.0  5132022       5    13   2022    1100.0  2022000436   \n",
      "1     9.0     1.0  2282022       2    28   2022    1200.0  2022005381   \n",
      "2    19.0     1.0  1202022       1    20   2022    1100.0  2022000927   \n",
      "3    39.0     8.0  8122022       8    12   2022    1100.0  2022014408   \n",
      "4    25.0     7.0  7222022       7    22   2022    1200.0  2022010910   \n",
      "\n",
      "           _PSU  CTELENM1  ...  DRNKANY6      DROCDY4_  _RFBING6  \\\n",
      "0  2.022000e+09       1.0  ...       1.0  2.700000e+01       1.0   \n",
      "1  2.022005e+09       NaN  ...       9.0  9.000000e+02       9.0   \n",
      "2  2.022001e+09       1.0  ...       2.0  5.397605e-79       1.0   \n",
      "3  2.022014e+09       NaN  ...       2.0  5.397605e-79       1.0   \n",
      "4  2.022011e+09       NaN  ...       1.0  1.700000e+01       2.0   \n",
      "\n",
      "       _DRNKWK2  _RFDRHV8  _FLSHOT7  _PNEUMO3  _AIDTST4  ID  TARGET  \n",
      "0  1.870000e+02       1.0       1.0       1.0       2.0   0    True  \n",
      "1  9.990000e+04       9.0       NaN       NaN       NaN   1   False  \n",
      "2  5.397605e-79       1.0       NaN       NaN       9.0   2   False  \n",
      "3  5.397605e-79       1.0       NaN       NaN       2.0   3   False  \n",
      "4  4.670000e+02       1.0       NaN       NaN       2.0   4   False  \n",
      "\n",
      "[5 rows x 325 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61bab05",
   "metadata": {},
   "source": [
    "# Colonnes √† √©liminer \n",
    "\n",
    "## Tri manuel (bulle)\n",
    "\n",
    "- FMONTH\n",
    "- IDATE\n",
    "- IMONTH\n",
    "- IYEAR\n",
    "- IDAY\n",
    "- SEQNO\n",
    "- _PSU\n",
    "- CTELENM1\n",
    "- PVTRESD1\n",
    "- COLGHOUS\n",
    "- STATERE1\n",
    "- CELPHON1\n",
    "- LADULT1\n",
    "- COLGSEX1\n",
    "- NUMADULT\n",
    "- NUMMEN\n",
    "- NUMWOMEN\n",
    "- RESPSLCT\n",
    "- LANDSEX1\n",
    "- CELLSEX1\n",
    "- SAFETIME\n",
    "- CTELNUM1\n",
    "- CELLFON5\n",
    "- CADULT1\n",
    "- PVTRESD3\n",
    "- CCLGHOUS\n",
    "- CSTATE1\n",
    "- LANDLINE\n",
    "- HHADULT\n",
    "- LASTDEN4\n",
    "- RMVTETH4\n",
    "- NUMHHOL4\n",
    "- VIRCOLO1\n",
    "- TOLDCFS\n",
    "- HAVECFS\n",
    "- WORKCFS\n",
    "- CAREGIV1\n",
    "- CRGVREL4\n",
    "- CSRVSUM\n",
    "- CRGVLNG1\n",
    "- CRGVHRS1\n",
    "- CRGVPRB3\n",
    "- CRGVALZD\n",
    "- CRGVPER1\n",
    "- CRGVHOU1\n",
    "- CRGVEXPT\n",
    "- FIREARM5\n",
    "- GUNLOAD\n",
    "- LOADULK2\n",
    "- RCSGEND1\n",
    "- RCSXBRTH\n",
    "- RCSRLTN2\n",
    "- CASTHDX2\n",
    "- CASTHNO2\n",
    "- BIRTHSEX\n",
    "- WHEREGET\n",
    "- NOBCUSE8\n",
    "- RRCOGNT2\n",
    "- QSTVER\n",
    "- QSTLANG\n",
    "- _STSTR\n",
    "- _STRWT\n",
    "- _RAWRAKE\n",
    "- _WT2RAKE\n",
    "- CAGEG\n",
    "- _CLLCPWT\n",
    "- _DUALUSE\n",
    "- _DUALCOR\n",
    "- _LLCPWT2\n",
    "- _LLCPWT\n",
    "- _EXTETH3\n",
    "- _ALTETH3\n",
    "- _DENVST3\n",
    "- _PRACE2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c69a519",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r√©duit = df_train.drop(columns=[\n",
    "    'FMONTH', 'IDATE', 'IMONTH', 'IYEAR', 'IDAY', 'SEQNO', '_PSU', 'CTELENM1', \n",
    "    'PVTRESD1', 'COLGHOUS', 'STATERE1', 'CELPHON1', 'LADULT1', 'COLGSEX1', \n",
    "    'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'RESPSLCT', 'LANDSEX1', 'CELLSEX1', \n",
    "    'SAFETIME', 'CTELNUM1', 'CELLFON5', 'CADULT1', 'PVTRESD3', 'CCLGHOUS', \n",
    "    'CSTATE1', 'LANDLINE', 'HHADULT', 'LASTDEN4', 'RMVTETH4', 'NUMHHOL4', \n",
    "    'VIRCOLO1', 'TOLDCFS', 'HAVECFS', 'WORKCFS', 'CAREGIV1', 'CRGVREL4', \n",
    "    'CSRVSUM', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB3', 'CRGVALZD', 'CRGVPER1', \n",
    "    'CRGVHOU1', 'CRGVEXPT', 'FIREARM5', 'GUNLOAD', 'LOADULK2', 'RCSGEND1', \n",
    "    'RCSXBRTH', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'BIRTHSEX', 'WHEREGET', \n",
    "    'NOBCUSE8', 'RRCOGNT2', 'QSTVER', 'QSTLANG', '_STSTR', '_STRWT', \n",
    "    '_RAWRAKE', '_WT2RAKE', 'CAGEG', '_CLLCPWT', '_DUALUSE', '_DUALCOR', \n",
    "    '_LLCPWT2', '_LLCPWT', '_EXTETH3', '_ALTETH3', '_DENVST3', '_PRACE2'\n",
    "])\n",
    "\n",
    "df_test = df_test.drop(columns=[\n",
    "    'FMONTH', 'IDATE', 'IMONTH', 'IYEAR', 'IDAY', 'SEQNO', '_PSU', 'CTELENM1', \n",
    "    'PVTRESD1', 'COLGHOUS', 'STATERE1', 'CELPHON1', 'LADULT1', 'COLGSEX1', \n",
    "    'NUMADULT', 'NUMMEN', 'NUMWOMEN', 'RESPSLCT', 'LANDSEX1', 'CELLSEX1', \n",
    "    'SAFETIME', 'CTELNUM1', 'CELLFON5', 'CADULT1', 'PVTRESD3', 'CCLGHOUS', \n",
    "    'CSTATE1', 'LANDLINE', 'HHADULT', 'LASTDEN4', 'RMVTETH4', 'NUMHHOL4', \n",
    "    'VIRCOLO1', 'TOLDCFS', 'HAVECFS', 'WORKCFS', 'CAREGIV1', 'CRGVREL4', \n",
    "    'CSRVSUM', 'CRGVLNG1', 'CRGVHRS1', 'CRGVPRB3', 'CRGVALZD', 'CRGVPER1', \n",
    "    'CRGVHOU1', 'CRGVEXPT', 'FIREARM5', 'GUNLOAD', 'LOADULK2', 'RCSGEND1', \n",
    "    'RCSXBRTH', 'RCSRLTN2', 'CASTHDX2', 'CASTHNO2', 'BIRTHSEX', 'WHEREGET', \n",
    "    'NOBCUSE8', 'RRCOGNT2', 'QSTVER', 'QSTLANG', '_STSTR', '_STRWT', \n",
    "    '_RAWRAKE', '_WT2RAKE', 'CAGEG', '_CLLCPWT', '_DUALUSE', '_DUALCOR', \n",
    "    '_LLCPWT2', '_LLCPWT', '_EXTETH3', '_ALTETH3', '_DENVST3', '_PRACE2'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdefef71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on remplace les valeurs \"missing\" cod√©es par NaN\n",
    "missing_values = [7, 9, 77, 99, 777, 999, 9999]\n",
    "df_r√©duit = df_r√©duit.replace(missing_values, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3aa9ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64    250\n",
      "bool         1\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "üîπ Variables num√©riques continues : 10\n",
      "['WEIGHT2', 'HEIGHT3', 'LCSNUMCG', 'HIVTSTD3', 'WTKG3', '_BMI5', '_PACKDAY', '_PACKYRS', '_DRNKWK2', 'ID'] \n",
      "\n",
      "üîπ Variables binaires : 195\n",
      "['DISPCODE', 'SEXVAR', 'GENHLTH', 'PERSDOC3', 'MEDCOST1', 'CHECKUP1', 'EXERANY2', 'CVDSTRK3', 'ASTHMA3', 'ASTHNOW'] \n",
      "\n",
      "üîπ Variables cat√©gorielles : 20\n",
      "['PRIMINSR', 'SLEPTIM1', 'NUMPHON4', 'CPDEMO1C', 'EMPLOY1', 'CHILDREN', 'INCOME3', 'COVIDPRM', 'PDIABTS1', 'DIABEDU1'] \n",
      "\n",
      "‚ö†Ô∏è Colonnes non class√©es : 26\n",
      "['_STATE', 'PHYSHLTH', 'MENTHLTH', 'POORHLTH', 'DIABAGE4', 'LCSFIRST', 'LCSLAST', 'ALCDAY4', 'AVEDRNK3', 'DRNK3GE5', 'MAXDRNKS', 'FLSHTMY3', 'CHKHEMO3', 'COVIDFS1', 'COVIDSE1', 'COPDSMOK', 'CNCRAGE', 'CNCRTYP2', 'MARIJAN1', '_AGE80', 'HTIN4', 'HTM4', '_YRSSMOK', '_YRSQUIT', 'DROCDY4_', 'TARGET'] \n",
      "\n",
      "Total colonnes class√©es : 225\n",
      "Total colonnes dans df_r√©duit : 251\n",
      "----------------------------------------------------\n",
      "üîç V√©rification manuelle des premi√®res colonnes d√©tect√©es :\n",
      "\n",
      "DISPCODE: [1100. 1200.]\n",
      "SEXVAR: [2. 1.]\n",
      "GENHLTH: [ 3.  2.  4.  1.  5. nan]\n",
      "PRIMINSR: [ 3. 10.  1. nan  2.  5. 88.  6.  4.  8.]\n",
      "SLEPTIM1: [nan  6.  8. 10.  4. 15.  5.  2. 12.  3.]\n",
      "NUMPHON4: [ 2. nan  1.  3.  4.  8.  5.  6.]\n",
      "WEIGHT2: [165. 143. 285. 245. 180. 215. 200. 250. 210. 129.]\n",
      "HEIGHT3: [502. 511. 600. 601. 509. 503. 501.  nan 504. 507.]\n",
      "LCSNUMCG: [40. nan 15. 10. 20. 35.  3.  1.  6.  5.]\n"
     ]
    }
   ],
   "source": [
    "# FEATURE TYPE DETECTION (Version optimis√©e)\n",
    "\n",
    "# Aper√ßu des types de donn√©es\n",
    "print(df_r√©duit.dtypes.value_counts(), \"\\n\")\n",
    "\n",
    "# Colonnes num√©riques continues (valeurs nombreuses)\n",
    "# Seuil : > 100 valeurs distinctes\n",
    "numeric_features = [\n",
    "    col for col in df_r√©duit.columns\n",
    "    if df_r√©duit[col].dtype in ['int64', 'float64'] and df_r√©duit[col].nunique(dropna=True) > 100\n",
    "]\n",
    "\n",
    "# Colonnes binaires (souvent Oui/Non ou codes 1/2/7/9)\n",
    "# Seuil : ‚â§ 6 valeurs distinctes (certaines colonnes ont 1,2,7,9)\n",
    "binary_features = [\n",
    "    col for col in df_r√©duit.columns\n",
    "    if df_r√©duit[col].dtype in ['int64', 'float64'] and 2 <= df_r√©duit[col].nunique(dropna=True) <= 6\n",
    "]\n",
    "\n",
    "# Colonnes cat√©gorielles discr√®tes\n",
    "categorical_features = [\n",
    "    col for col in df_r√©duit.columns\n",
    "    if df_r√©duit[col].dtype in ['int64', 'float64'] and 7 <= df_r√©duit[col].nunique(dropna=True) <= 25\n",
    "]\n",
    "\n",
    "# Colonnes textuelles ou non num√©riques\n",
    "text_features = df_r√©duit.select_dtypes('object').columns.tolist()\n",
    "\n",
    "# --- 5Ô∏è‚É£ R√©sum√© clair\n",
    "print(\"üîπ Variables num√©riques continues :\", len(numeric_features))\n",
    "print(numeric_features[:10], \"\\n\")\n",
    "\n",
    "print(\"üîπ Variables binaires :\", len(binary_features))\n",
    "print(binary_features[:10], \"\\n\")\n",
    "\n",
    "print(\"üîπ Variables cat√©gorielles :\", len(categorical_features))\n",
    "print(categorical_features[:10], \"\\n\")\n",
    "\n",
    "if len(text_features) > 0:\n",
    "    print(\"üîπ Variables textuelles :\", len(text_features))\n",
    "    print(text_features, \"\\n\")\n",
    "\n",
    "# V√©rification de la couverture\n",
    "classified = set(numeric_features + binary_features + categorical_features + text_features)\n",
    "unclassified = [c for c in df_r√©duit.columns if c not in classified]\n",
    "\n",
    "print(\"‚ö†Ô∏è Colonnes non class√©es :\", len(unclassified))\n",
    "if unclassified:\n",
    "    print(unclassified, \"\\n\")\n",
    "\n",
    "print(\"Total colonnes class√©es :\", len(classified))\n",
    "print(\"Total colonnes dans df_r√©duit :\", df_r√©duit.shape[1])\n",
    "\n",
    "# --- 7Ô∏è‚É£ Exemple de valeurs pour v√©rification\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"üîç V√©rification manuelle des premi√®res colonnes d√©tect√©es :\\n\")\n",
    "\n",
    "for col in (binary_features[:3] + categorical_features[:3] + numeric_features[:3]):\n",
    "    print(f\"{col}: {df_r√©duit[col].unique()[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42af1044",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in binary_features:\n",
    "    df_r√©duit[col] = df_r√©duit[col].map({1: 1, 2: 0})\n",
    "\n",
    "\n",
    "for col in binary_features:\n",
    "    # Remplacer les codes manquants\n",
    "    df_r√©duit[col] = df_r√©duit[col].replace({7: np.nan, 9: np.nan, 77: np.nan, 99: np.nan})\n",
    "    # Mapper 1 ‚Üí 1 et 2 ‚Üí 0\n",
    "    df_r√©duit[col] = df_r√©duit[col].replace({1: 1, 2: 0})\n",
    "    # Remplacer les NaN par 0 ou 1 al√©atoirement\n",
    "    df_r√©duit[col] = df_r√©duit[col].replace({np.nan: np.random.choice([0, 1])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09f06a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_features:\n",
    "    for col in categorical_features:\n",
    "        df_r√©duit[col] = df_r√©duit[col].replace({np.nan: np.random.randint([1, df_r√©duit[col].nunique(dropna=True)])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be11449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================\n",
    "# üß© NETTOYAGE ET NORMALISATION DES VARIABLES CONTINUES\n",
    "# ======================================================\n",
    "\n",
    "for col in numeric_features:\n",
    "    if col in df_r√©duit.columns:\n",
    "        # --- 1Ô∏è‚É£ Remplacer les codes aberrants / manquants\n",
    "        df_r√©duit[col] = df_r√©duit[col].replace([7, 9, 77, 99, 777, 999, 7777, 9999, 99999], np.nan)\n",
    "\n",
    "        # --- 2Ô∏è‚É£ Imputation des valeurs manquantes (m√©diane)\n",
    "        df_r√©duit[col] = df_r√©duit[col].replace({np.nan: np.random.normal([df_r√©duit[col].min(), df_r√©duit[col].max()])})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dcd8ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>DISPCODE</th>\n",
       "      <th>SEXVAR</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>MENTHLTH</th>\n",
       "      <th>POORHLTH</th>\n",
       "      <th>PRIMINSR</th>\n",
       "      <th>PERSDOC3</th>\n",
       "      <th>MEDCOST1</th>\n",
       "      <th>...</th>\n",
       "      <th>DRNKANY6</th>\n",
       "      <th>DROCDY4_</th>\n",
       "      <th>_RFBING6</th>\n",
       "      <th>_DRNKWK2</th>\n",
       "      <th>_RFDRHV8</th>\n",
       "      <th>_FLSHOT7</th>\n",
       "      <th>_PNEUMO3</th>\n",
       "      <th>_AIDTST4</th>\n",
       "      <th>ID</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.870000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000e+02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.990000e+04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.700000e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.670000e+02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE  DISPCODE  SEXVAR  GENHLTH  PHYSHLTH  MENTHLTH  POORHLTH  PRIMINSR  \\\n",
       "0     2.0       1.0       0      0.0      30.0      88.0      88.0       3.0   \n",
       "1     NaN       1.0       0      0.0      88.0      15.0      14.0      10.0   \n",
       "2    19.0       1.0       1      0.0      88.0      88.0       NaN       1.0   \n",
       "3    39.0       1.0       1      0.0      88.0      88.0       NaN       1.0   \n",
       "4    25.0       1.0       1      0.0      88.0       3.0      88.0       0.0   \n",
       "\n",
       "   PERSDOC3  MEDCOST1  ...  DRNKANY6      DROCDY4_  _RFBING6      _DRNKWK2  \\\n",
       "0       1.0       0.0  ...       1.0  2.700000e+01       1.0  1.870000e+02   \n",
       "1       0.0       0.0  ...       1.0  9.000000e+02       0.0  9.990000e+04   \n",
       "2       1.0       0.0  ...       0.0  5.397605e-79       1.0  5.397605e-79   \n",
       "3       1.0       0.0  ...       0.0  5.397605e-79       1.0  5.397605e-79   \n",
       "4       0.0       0.0  ...       1.0  1.700000e+01       0.0  4.670000e+02   \n",
       "\n",
       "   _RFDRHV8  _FLSHOT7  _PNEUMO3  _AIDTST4   ID  TARGET  \n",
       "0       1.0       1.0       1.0       0.0  0.0    True  \n",
       "1       1.0       1.0       1.0       1.0  1.0   False  \n",
       "2       1.0       1.0       1.0       1.0  2.0   False  \n",
       "3       1.0       1.0       1.0       0.0  3.0   False  \n",
       "4       1.0       1.0       1.0       0.0  4.0   False  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r√©duit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f95b3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_r√©duit.drop(columns=['TARGET']), df_r√©duit['TARGET']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split stratifi√© du jeu d'entra√Ænement en train / validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.3, stratify=y_train, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30a8a160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:19:23] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.99      0.95     61458\n",
      "        True       0.49      0.13      0.21      6042\n",
      "\n",
      "    accuracy                           0.91     67500\n",
      "   macro avg       0.70      0.56      0.58     67500\n",
      "weighted avg       0.88      0.91      0.89     67500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "model_xgb = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_xgb.fit(X_tr, y_tr)\n",
    "y_pred_xgb = model_xgb.predict(X_val)\n",
    "print(classification_report(y_val, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7216ebd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training RandomForest:   3%|‚ñé         | 3/100 [00:03<01:37,  1.00s/est]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_estimators):\n\u001b[32m     10\u001b[39m         model.n_estimators = i + \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m         pbar.update(\u001b[32m1\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# On √©value le mod√®le \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:486\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    475\u001b[39m trees = [\n\u001b[32m    476\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    478\u001b[39m ]\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "n_estimators = 100\n",
    "# On utilise warm_start pour faire grandir la for√™t progressivement et afficher la progression\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, warm_start=True, n_jobs=-1)\n",
    "\n",
    "with tqdm(total=n_estimators, desc=\"Training RandomForest\", unit=\"est\") as pbar:\n",
    "    for i in range(n_estimators):\n",
    "        model.n_estimators = i + 1\n",
    "        model.fit(X_train, y_train)\n",
    "        pbar.update(1)\n",
    "\n",
    "# On √©value le mod√®le \n",
    "y_pred_rf = model.predict(X_train)\n",
    "\n",
    "print(classification_report(y_train, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2a0486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier cr√©√©: submission.csv\n",
      "       ID  TARGET\n",
      "0  225000       0\n",
      "1  225001       0\n",
      "2  225002       0\n",
      "3  225003       0\n",
      "4  225004       0\n"
     ]
    }
   ],
   "source": [
    "# G√©n√©ration du fichier de soumission (ID, TARGET) √† partir du test set\n",
    "\n",
    "# Aligner les features du test sur celles utilis√©es par le mod√®le\n",
    "X_test = df_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Pr√©diction binaire sur le test set\n",
    "y_pred_test = model_xgb.predict(X_test).astype(int)\n",
    "\n",
    "# Construire et sauvegarder le fichier de soumission\n",
    "submission = pd.DataFrame({\n",
    "    'ID': df_test['ID'],\n",
    "    'TARGET': y_pred_test\n",
    "})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Fichier cr√©√©: submission.csv\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e5aae8",
   "metadata": {},
   "source": [
    "## Resampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df0b51e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes -> X_tr: (180000, 250) X_val: (45000, 250) y_tr: (180000,) y_val: (45000,)\n",
      "\n",
      "R√©partition TARGET (train):\n",
      " TARGET\n",
      "False    0.910494\n",
      "True     0.089506\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "R√©partition TARGET (val):\n",
      " TARGET\n",
      "False    0.910489\n",
      "True     0.089511\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Variable 'model' (RandomForest) non trouv√©e.\n",
      "\n",
      "XGBoost (validation):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.92      0.99      0.95     40972\n",
      "        True       0.50      0.14      0.21      4028\n",
      "\n",
      "    accuracy                           0.91     45000\n",
      "   macro avg       0.71      0.56      0.58     45000\n",
      "weighted avg       0.88      0.91      0.89     45000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Split stratifi√© du jeu d'entra√Ænement en train / validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, stratify=y_train, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Shapes -> X_tr:\", X_tr.shape, \"X_val:\", X_val.shape, \"y_tr:\", y_tr.shape, \"y_val:\", y_val.shape)\n",
    "print(\"\\nR√©partition TARGET (train):\\n\", y_tr.value_counts(normalize=True))\n",
    "print(\"\\nR√©partition TARGET (val):\\n\", y_val.value_counts(normalize=True))\n",
    "\n",
    "# √âvaluer les mod√®les existants sur la validation (si pr√©sents)\n",
    "if 'model' in globals():\n",
    "    y_pred_val_rf = model.predict(X_val)\n",
    "    print(\"\\nRandomForest (validation):\")\n",
    "    print(classification_report(y_val, y_pred_val_rf))\n",
    "else:\n",
    "    print(\"\\nVariable 'model' (RandomForest) non trouv√©e.\")\n",
    "\n",
    "if 'model_xgb' in globals():\n",
    "    y_pred_val_xgb = model_xgb.predict(X_val)\n",
    "    print(\"\\nXGBoost (validation):\")\n",
    "    print(classification_report(y_val, y_pred_val_xgb))\n",
    "else:\n",
    "    print(\"\\nVariable 'model_xgb' (XGBoost) non trouv√©e.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f786d68f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "False    0.7\n",
      "True     0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# S√©parer les classes\n",
    "X_1 = X_train[y_train == 1]\n",
    "X_0 = X_train[y_train == 0]\n",
    "y_1 = y_train[y_train == 1]\n",
    "y_0 = y_train[y_train == 0]\n",
    "\n",
    "# Calcul du nombre total pour obtenir 30% de 1\n",
    "n_total = len(y_train)\n",
    "n_1_target = int(n_total * 0.3)\n",
    "n_0_target = n_total - n_1_target\n",
    "\n",
    "# Sur-√©chantillonnage des 1\n",
    "X_1_oversampled = X_1.sample(n=n_1_target, replace=True, random_state=42)\n",
    "y_1_oversampled = y_1.sample(n=n_1_target, replace=True, random_state=42)\n",
    "\n",
    "# Sous-√©chantillonnage des 0\n",
    "X_0_undersampled = X_0.sample(n=n_0_target, random_state=42)\n",
    "y_0_undersampled = y_0.sample(n=n_0_target, random_state=42)\n",
    "\n",
    "# Concat√©ner\n",
    "X_train_balanced = pd.concat([X_1_oversampled, X_0_undersampled])\n",
    "y_train_balanced = pd.concat([y_1_oversampled, y_0_undersampled])\n",
    "\n",
    "# M√©langer\n",
    "X_train_balanced, y_train_balanced = X_train_balanced.sample(frac=1, random_state=42), y_train_balanced.sample(frac=1, random_state=42)\n",
    "\n",
    "print(y_train_balanced.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c814515",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:19:39] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.88      0.91      0.90    157500\n",
      "        True       0.77      0.71      0.74     67500\n",
      "\n",
      "    accuracy                           0.85    225000\n",
      "   macro avg       0.83      0.81      0.82    225000\n",
      "weighted avg       0.85      0.85      0.85    225000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Adapter XGBoost aux donn√©es augment√©es (√©quilibr√©es)\n",
    "model_xgb_balanced = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "model_xgb_balanced.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred_xgb_balanced = model_xgb_balanced.predict(X_train_balanced)\n",
    "print(classification_report(y_train_balanced, y_pred_xgb_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f352a892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©but de la recherche de grille...\n",
      "Fitting 5 folds for each of 15552 candidates, totalling 77760 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/xgboost/training.py:183: UserWarning: [09:26:05] WARNING: /var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_abwcuua5oq/croot/xgboost-split_1749630928197/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mD√©but de la recherche de grille...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_balanced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     28\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mErreur lors de l\u001b[39m\u001b[33m'\u001b[39m\u001b[33mentra√Ænement avec GridSearchCV: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/model_selection/_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/utils/parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/joblib/parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "# D√©finir les param√®tres pour GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Cr√©er le mod√®le XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1_weighted', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entra√Æner le mod√®le avec GridSearch\n",
    "print(\"D√©but de la recherche de grille...\")\n",
    "try:\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'entra√Ænement avec GridSearchCV: {e}\")\n",
    "\n",
    "# Afficher les meilleurs param√®tres et le meilleur score\n",
    "print(\"Meilleurs param√®tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur score:\", grid_search.best_score_)\n",
    "\n",
    "# Entra√Æner le meilleur mod√®le final\n",
    "best_model_grid = grid_search.best_estimator_\n",
    "\n",
    "# Pr√©diction sur le jeu de validation\n",
    "y_pred_val_grid = best_model_grid.predict(X_val)\n",
    "print(\"\\nüìà Performance sur validation:\")\n",
    "print(classification_report(y_val, y_pred_val_grid))\n",
    "\n",
    "# G√©n√©ration du fichier de soumission\n",
    "X_test = df_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "y_pred_test_grid = best_model_grid.predict(X_test).astype(int)\n",
    "\n",
    "submission_grid = pd.DataFrame({\n",
    "    'ID': df_test['ID'],\n",
    "    'TARGET': y_pred_test_grid\n",
    "})\n",
    "\n",
    "submission_grid.to_csv('submission_grid.csv', index=False)\n",
    "print(\"‚úÖ Fichier cr√©√©: submission_grid.csv\")\n",
    "print(submission_grid.head())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbbb8b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≤ D√©but du RandomizedSearch manuel (50 it√©rations) avec barre de progression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomizedSearch (params):   2%|‚ñè         | 1/50 [00:07<05:54,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelle meilleure score 0.7908 ‚Äî params: {'subsample': 0.9, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 100, 'min_child_weight': 3, 'max_depth': 3, 'learning_rate': 0.3, 'gamma': 0.3, 'colsample_bytree': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomizedSearch (params):   4%|‚ñç         | 2/50 [00:46<20:49, 26.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelle meilleure score 0.9507 ‚Äî params: {'subsample': 0.6, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 200, 'min_child_weight': 3, 'max_depth': 15, 'learning_rate': 0.3, 'gamma': 0, 'colsample_bytree': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomizedSearch (params):  28%|‚ñà‚ñà‚ñä       | 14/50 [07:47<30:29, 50.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelle meilleure score 0.9531 ‚Äî params: {'subsample': 0.6, 'reg_lambda': 1.0, 'reg_alpha': 0.5, 'n_estimators': 500, 'min_child_weight': 3, 'max_depth': 15, 'learning_rate': 0.3, 'gamma': 0, 'colsample_bytree': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomizedSearch (params):  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 27/50 [34:24<28:11, 73.56s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelle meilleure score 0.9587 ‚Äî params: {'subsample': 0.7, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 15, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RandomizedSearch (params): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [45:53<00:00, 55.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 param√®tres (apr√®s recherche):\n",
      "   subsample  reg_lambda  reg_alpha  n_estimators  min_child_weight  \\\n",
      "0        0.7         1.0        0.1           500                 1   \n",
      "1        1.0         1.0        1.0           500                 1   \n",
      "2        1.0         1.0        0.5           200                 3   \n",
      "3        0.6         1.0        0.5           500                 3   \n",
      "4        0.6         1.0        0.1           200                 3   \n",
      "\n",
      "   max_depth  learning_rate  gamma  colsample_bytree  mean_test_score  \\\n",
      "0         15           0.05    0.2               0.7         0.958658   \n",
      "1         15           0.05    0.2               0.9         0.957175   \n",
      "2         15           0.20    0.0               0.7         0.955058   \n",
      "3         15           0.30    0.0               0.7         0.953113   \n",
      "4         15           0.30    0.0               1.0         0.950674   \n",
      "\n",
      "   std_test_score  \n",
      "0        0.000873  \n",
      "1        0.000554  \n",
      "2        0.000941  \n",
      "3        0.000480  \n",
      "4        0.000675  \n",
      "\n",
      "Meilleur score global (cv f1_weighted): 0.9587\n",
      "\n",
      "üìà Performance sur validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.97      0.98     40972\n",
      "        True       0.78      0.97      0.86      4028\n",
      "\n",
      "    accuracy                           0.97     45000\n",
      "   macro avg       0.89      0.97      0.92     45000\n",
      "weighted avg       0.98      0.97      0.97     45000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterSampler, StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ======================================================\n",
    "# üé≤ RECHERCHE MANUELLE (RANDOMIZED) AVEC BARRE DE PROGRESSION (outer + inner)\n",
    "# ======================================================\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 5, 7, 10, 15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 3, 5, 7],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3, 0.5],\n",
    "    'reg_alpha': [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda': [0, 0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42, verbosity=0)\n",
    "scorer = make_scorer(f1_score, average='weighted')\n",
    "\n",
    "n_iter = 50\n",
    "sampler = list(ParameterSampler(param_distributions, n_iter=n_iter, random_state=42))\n",
    "\n",
    "best_score = -np.inf\n",
    "best_params = None\n",
    "results = []\n",
    "\n",
    "print(f\"üé≤ D√©but du RandomizedSearch manuel ({n_iter} it√©rations) avec barre de progression...\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, params in enumerate(tqdm(sampler, desc=\"RandomizedSearch (params)\", unit=\"it\")):\n",
    "    fold_scores = []\n",
    "    # inner progress per fold\n",
    "    for train_idx, valid_idx in tqdm(cv.split(X_train_balanced, y_train_balanced),\n",
    "                                    desc=f\"params {i+1}/{n_iter} folds\",\n",
    "                                    total=cv.get_n_splits(),\n",
    "                                    leave=False,\n",
    "                                    unit=\"fold\"):\n",
    "        m = clone(xgb_model).set_params(**params)\n",
    "        m.fit(X_train_balanced.iloc[train_idx], y_train_balanced.iloc[train_idx])\n",
    "        preds = m.predict(X_train_balanced.iloc[valid_idx])\n",
    "        fold_scores.append(f1_score(y_train_balanced.iloc[valid_idx], preds, average='weighted'))\n",
    "\n",
    "    mean_score = float(np.mean(fold_scores))\n",
    "    std_score = float(np.std(fold_scores))\n",
    "    results.append({**params, 'mean_test_score': mean_score, 'std_test_score': std_score})\n",
    "\n",
    "    # print progress if improvement\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "        print(f\"Nouvelle meilleure score {best_score:.4f} ‚Äî params: {best_params}\")\n",
    "\n",
    "# r√©sultat final\n",
    "results_df = pd.DataFrame(results).sort_values('mean_test_score', ascending=False).reset_index(drop=True)\n",
    "print(\"\\nTop 5 param√®tres (apr√®s recherche):\")\n",
    "print(results_df.head(5))\n",
    "print(f\"\\nMeilleur score global (cv f1_weighted): {best_score:.4f}\")\n",
    "\n",
    "# Entra√Æner le meilleur mod√®le final sur X_train_balanced\n",
    "best_model_random = clone(xgb_model).set_params(**best_params)\n",
    "best_model_random.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "y_pred_val_random = best_model_random.predict(X_val)\n",
    "print(\"\\nüìà Performance sur validation:\")\n",
    "print(classification_report(y_val, y_pred_val_random))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5f9a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D√©but de la recherche de grille...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Recherche de param√®tres:   0%|          | 0/15552 [00:00<?, ?param/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'colsample_bytree' for estimator GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False,\n                                     eval_metric='logloss', feature_types=None,\n                                     feature_weights=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraint...\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None, ...),\n             n_jobs=-1,\n             param_grid={'colsample_bytree': [0.6, 0.8, 1.0],\n                         'gamma': [0, 0.1, 0.3, 0.5],\n                         'learning_rate': [0.01, 0.05, 0.1, 0.2],\n                         'max_depth': [3, 5, 7, 9],\n                         'n_estimators': [100, 200, 300],\n                         'reg_alpha': [0, 0.01, 0.1], 'reg_lambda': [1, 1.5, 2],\n                         'subsample': [0.6, 0.8, 1.0]},\n             scoring='f1_weighted', verbose=1). Valid parameters are: ['cv', 'error_score', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mD√©but de la recherche de grille...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m tqdm(ParameterGrid(param_grid), desc=\u001b[33m\"\u001b[39m\u001b[33mRecherche de param√®tres\u001b[39m\u001b[33m\"\u001b[39m, unit=\u001b[33m\"\u001b[39m\u001b[33mparam\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     \u001b[43mgrid_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     29\u001b[39m         grid_search.fit(X_train_balanced, y_train_balanced)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/myenv/lib/python3.13/site-packages/sklearn/base.py:345\u001b[39m, in \u001b[36mBaseEstimator.set_params\u001b[39m\u001b[34m(self, **params)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_params:\n\u001b[32m    344\u001b[39m     local_valid_params = \u001b[38;5;28mself\u001b[39m._get_param_names()\n\u001b[32m--> \u001b[39m\u001b[32m345\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    346\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m for estimator \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    347\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mValid parameters are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_valid_params\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m     )\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m delim:\n\u001b[32m    351\u001b[39m     nested_params[key][sub_key] = value\n",
      "\u001b[31mValueError\u001b[39m: Invalid parameter 'colsample_bytree' for estimator GridSearchCV(cv=5,\n             estimator=XGBClassifier(base_score=None, booster=None,\n                                     callbacks=None, colsample_bylevel=None,\n                                     colsample_bynode=None,\n                                     colsample_bytree=None, device=None,\n                                     early_stopping_rounds=None,\n                                     enable_categorical=False,\n                                     eval_metric='logloss', feature_types=None,\n                                     feature_weights=None, gamma=None,\n                                     grow_policy=None, importance_type=None,\n                                     interaction_constraint...\n                                     multi_strategy=None, n_estimators=None,\n                                     n_jobs=None, num_parallel_tree=None, ...),\n             n_jobs=-1,\n             param_grid={'colsample_bytree': [0.6, 0.8, 1.0],\n                         'gamma': [0, 0.1, 0.3, 0.5],\n                         'learning_rate': [0.01, 0.05, 0.1, 0.2],\n                         'max_depth': [3, 5, 7, 9],\n                         'n_estimators': [100, 200, 300],\n                         'reg_alpha': [0, 0.01, 0.1], 'reg_lambda': [1, 1.5, 2],\n                         'subsample': [0.6, 0.8, 1.0]},\n             scoring='f1_weighted', verbose=1). Valid parameters are: ['cv', 'error_score', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose']."
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "\n",
    "# D√©finir les param√®tres pour GridSearch\n",
    "param_grid = {  # Changement ici\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.3, 0.5],\n",
    "    'reg_alpha': [0, 0.01, 0.1],\n",
    "    'reg_lambda': [1, 1.5, 2]\n",
    "}\n",
    "\n",
    "# Cr√©er le mod√®le XGBoost\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Configurer GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='f1_weighted', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Entra√Æner le mod√®le avec GridSearch et afficher les param√®tres\n",
    "print(\"D√©but de la recherche de grille...\")\n",
    "for params in tqdm(ParameterGrid(param_grid), desc=\"Recherche de param√®tres\", unit=\"param\"):\n",
    "    grid_search.set_params(**params)\n",
    "    try:\n",
    "        grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "        print(f\"Param√®tres: {params} ‚Äî Meilleur score: {grid_search.best_score_:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'entra√Ænement avec les param√®tres {params}: {e}\")\n",
    "\n",
    "# Afficher les meilleurs param√®tres et le meilleur score\n",
    "print(\"Meilleurs param√®tres:\", grid_search.best_params_)\n",
    "print(\"Meilleur score:\", grid_search.best_score_)\n",
    "\n",
    "# Entra√Æner le meilleur mod√®le final\n",
    "best_model_grid = grid_search.best_estimator_\n",
    "\n",
    "# Pr√©diction sur le jeu de validation\n",
    "y_pred_val_grid = best_model_grid.predict(X_val)\n",
    "print(\"\\nüìà Performance sur validation:\")\n",
    "print(classification_report(y_val, y_pred_val_grid))\n",
    "\n",
    "# G√©n√©ration du fichier de soumission\n",
    "X_test = df_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "y_pred_test_grid = best_model_grid.predict(X_test).astype(int)\n",
    "\n",
    "submission_grid = pd.DataFrame({\n",
    "    'ID': df_test['ID'],\n",
    "    'TARGET': y_pred_test_grid\n",
    "})\n",
    "\n",
    "submission_grid.to_csv('submission_grid.csv', index=False)\n",
    "print(\"‚úÖ Fichier cr√©√©: submission_grid.csv\")\n",
    "print(submission_grid.head())\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32de79c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model from: best_model_random\n",
      "‚úÖ Fichier cr√©√©: submission_optimized.csv\n",
      "       ID  TARGET\n",
      "0  225000       0\n",
      "1  225001       0\n",
      "2  225002       0\n",
      "3  225003       0\n",
      "4  225004       0\n",
      "\n",
      "R√©partition des pr√©dictions:\n",
      "TARGET\n",
      "0    0.999147\n",
      "1    0.000853\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "import numpy as np\n",
    "\n",
    "# choisir le meilleur mod√®le disponible\n",
    "if 'best_model_random' in globals() and best_model_random is not None:\n",
    "    chosen_model = best_model_random\n",
    "    source = 'best_model_random'\n",
    "elif 'random_search' in globals() and hasattr(random_search, 'best_estimator_'):\n",
    "    chosen_model = random_search.best_estimator_\n",
    "    source = 'random_search.best_estimator_'\n",
    "elif 'best_model_final' in globals() and best_model_final is not None:\n",
    "    chosen_model = best_model_final\n",
    "    source = 'best_model_final'\n",
    "else:\n",
    "    raise RuntimeError(\"Aucun mod√®le optimis√© trouv√©. Ex√©cute la cellule d'optimisation avant de g√©n√©rer la soumission.\")\n",
    "\n",
    "print(f\"Using model from: {source}\")\n",
    "\n",
    "# d√©terminer les colonnes attendues\n",
    "if hasattr(chosen_model, \"feature_names_in_\"):\n",
    "    feat_cols = list(chosen_model.feature_names_in_)\n",
    "else:\n",
    "    feat_cols = list(X_train.columns)\n",
    "\n",
    "# pr√©parer X_test (aligner colonnes, remplir NaN)\n",
    "X_test = df_test.reindex(columns=feat_cols, fill_value=0)\n",
    "# simple coercion pour √©viter erreurs de dtype / NaN ‚Äî adapter si vous avez des cat√©gories\n",
    "X_test = X_test.astype(float).fillna(0)\n",
    "\n",
    "# pr√©diction\n",
    "y_pred = chosen_model.predict(X_test)\n",
    "# garantir entiers binaires\n",
    "try:\n",
    "    y_pred = y_pred.astype(int)\n",
    "except:\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "\n",
    "# garantir colonne ID\n",
    "if 'ID' not in df_test.columns:\n",
    "    df_test['ID'] = df_test.index\n",
    "\n",
    "submission_optimized = pd.DataFrame({\n",
    "    'ID': df_test['ID'],\n",
    "    'TARGET': y_pred\n",
    "})\n",
    "\n",
    "submission_optimized.to_csv('submission_optimized.csv', index=False)\n",
    "print(\"‚úÖ Fichier cr√©√©: submission_optimized.csv\")\n",
    "print(submission_optimized.head())\n",
    "print(\"\\nR√©partition des pr√©dictions:\")\n",
    "print(submission_optimized['TARGET'].value_counts(normalize=True))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "926f9230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier cr√©√©: submission_balanced.csv\n",
      "       ID  TARGET\n",
      "0  225000       1\n",
      "1  225001       1\n",
      "2  225002       0\n",
      "3  225003       1\n",
      "4  225004       1\n"
     ]
    }
   ],
   "source": [
    "# G√©n√©ration du fichier de soumission avec le mod√®le XGBoost √©quilibr√©\n",
    "\n",
    "# Aligner les features du test sur celles utilis√©es par le mod√®le\n",
    "X_test = df_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Pr√©diction binaire sur le test set avec le mod√®le √©quilibr√©\n",
    "y_pred_test_balanced = model_xgb_balanced.predict(X_test).astype(int)\n",
    "\n",
    "# Construire et sauvegarder le fichier de soumission\n",
    "submission_balanced = pd.DataFrame({\n",
    "    'ID': df_test['ID'],\n",
    "    'TARGET': y_pred_test_balanced\n",
    "})\n",
    "\n",
    "submission_balanced.to_csv('submission_balanced.csv', index=False)\n",
    "print(\"Fichier cr√©√©: submission_balanced.csv\")\n",
    "print(submission_balanced.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
